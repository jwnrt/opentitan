# Copyright lowRISC contributors.
# Licensed under the Apache License, Version 2.0, see LICENSE for details.
# SPDX-License-Identifier: Apache-2.0
#
# Azure Pipelines CI build configuration
# Documentation at https://aka.ms/yaml

variables:
  #
  # If updating VERILATOR_VERSION, TOOLCHAIN_VERSION, update the
  # definitions in util/container/Dockerfile as well.
  #
  VERILATOR_VERSION: 4.210
  TOOLCHAIN_PATH: /opt/buildcache/riscv
  VERIBLE_VERSION: v0.0-2135-gb534c1fe
  # Release tag from https://github.com/lowRISC/lowrisc-toolchains/releases
  TOOLCHAIN_VERSION: 20220210-1
  # This controls where builds happen, and gets picked up by build_consts.sh.
  BUILD_ROOT: $(Build.ArtifactStagingDirectory)
  VIVADO_VERSION: "2020.2"

trigger:
  batch: true
  branches:
    include:
    - "*"
  tags:
    include:
    - "*"
pr:
  branches:
    include:
    - "*"

jobs:
- job: checkout
  displayName: Checkout repository
  pool:
    vmImage: ubuntu-20.04
  steps:
  - checkout: self
    path: opentitan-repo
  - bash: |
      tar -C $(Pipeline.Workspace)/opentitan-repo -czf $(Pipeline.Workspace)/opentitan-repo.tar.gz .
    displayName: Pack up repository
  - publish: $(Pipeline.Workspace)/opentitan-repo.tar.gz
    artifact: opentitan-repo
    displayName: Upload repository
- job: lint
  displayName: Quality (quick lint)
  # Run code quality checks (quick lint)
  dependsOn: checkout
  pool: ci-public
  steps:
  - template: ci/checkout-template.yml
  - template: ci/install-package-dependencies.yml
    ## !!!
    ##
    ##   The steps below here are duplicated in ci/jobs/quick-lint.sh
    ##   to allow developers to "run CI" locally. Keep them in sync.
    ##
    ## !!!
  - bash: ci/scripts/show-env.sh
    displayName: Environment Info
    # Display environment information
  - bash: ci/scripts/lint-commits.sh $SYSTEM_PULLREQUEST_TARGETBRANCH
    condition: eq(variables['Build.Reason'], 'PullRequest')
    displayName: Commit metadata
  - bash: ci/scripts/check-licence-headers.sh $SYSTEM_PULLREQUEST_TARGETBRANCH
    condition: eq(variables['Build.Reason'], 'PullRequest')
    displayName: Licence Headers
  - bash: ci/scripts/exec-check.sh
    condition: eq(variables['Build.Reason'], 'PullRequest')
    displayName: Executable Bits
  - bash: ci/scripts/check-ascii.sh
    condition: eq(variables['Build.Reason'], 'PullRequest')
    displayName: ASCII Chars
    # Check for non-ASCII characters in source code
  - bash: ci/scripts/python-lint.sh $SYSTEM_PULLREQUEST_TARGETBRANCH
    condition: eq(variables['Build.Reason'], 'PullRequest')
    displayName: flake8 (Python lint)
    # Run Python lint (flake8)
  - bash: ci/scripts/mypy.sh
    condition: eq(variables['Build.Reason'], 'PullRequest')
    displayName: mypy (Python lint)
    # Run Python lint (mypy)
  - bash: ci/scripts/clang-format.sh $SYSTEM_PULLREQUEST_TARGETBRANCH
    condition: eq(variables['Build.Reason'], 'PullRequest')
    displayName: clang-format (C/C++ lint)
    # Use clang-format to check C/C++ coding style
  - bash: ci/scripts/rust-format.sh $SYSTEM_PULLREQUEST_TARGETBRANCH
    condition: eq(variables['Build.Reason'], 'PullRequest')
    displayName: rustfmt
  - bash: |
      ci/bazelisk.sh test //quality:shellcheck_check || {
        echo -n "##vso[task.logissue type=error]"
        echo "Shellcheck failed. Run util/sh/scripts/run-shellcheck.sh to see errors."
        exit 1
      }
    displayName: shellcheck
  - bash: ci/scripts/include-guard.sh $SYSTEM_PULLREQUEST_TARGETBRANCH
    condition: eq(variables['Build.Reason'], 'PullRequest')
    displayName: Header guards
    # Check formatting on header guards
  - bash: ci/scripts/whitespace.sh $SYSTEM_PULLREQUEST_TARGETBRANCH
    condition: eq(variables['Build.Reason'], 'PullRequest')
    displayName: Check trailing whitespace
  - bash: ci/scripts/build-docs.sh
    displayName: Render documentation
  - bash: ci/scripts/check-links.sh
    displayName: Check File Links
  - bash: ci/scripts/check-cmdgen.sh
    displayName: Check CMDGEN Blocks
  - bash: ci/scripts/get-build-type.sh "$SYSTEM_PULLREQUEST_TARGETBRANCH" "$(Build.Reason)"
    displayName: Type of change
    # Check what kinds of changes the PR contains
    name: DetermineBuildType
  - bash: ci/scripts/check-no-bazelrc-site.sh
    condition: eq(variables['Build.Reason'], 'PullRequest')
    displayName: Confirm no .bazelrc-site files

- job: sw_build
  displayName: Earl Grey SW Build & Test
  # Build and test Software for Earl Grey toplevel design
  timeoutInMinutes: 210
  dependsOn: lint
  condition: and(succeeded(), eq(dependencies.lint.outputs['DetermineBuildType.onlyDocChanges'], '0'), eq(dependencies.lint.outputs['DetermineBuildType.onlyCdcChanges'], '0'))
  pool: ci-public
  variables:
    - name: bazelCacheGcpKeyPath
      value: ''
  steps:
  - template: ci/checkout-template.yml
  - template: ci/install-package-dependencies.yml
  - task: DownloadSecureFile@1
    condition: eq(variables['Build.SourceBranchName'], 'master')
    name: bazelCacheGcpKey
    inputs:
      secureFile: "bazel_cache_gcp_key.json"
  - bash: echo "##vso[task.setvariable variable=bazelCacheGcpKeyPath]$(bazelCacheGcpKey.secureFilePath)"
    condition: eq(variables['Build.SourceBranchName'], 'master')
    displayName: GCP key path
    # Set the remote cache GCP key path
  - bash: |
      set -x -e
      # Check the entire build graph for conflicts in loading or analysis
      # phases. For context, see issue #18726.
      # First, test with an empty bitstream cache entry.
      ci/scripts/test-empty-bitstream-cache.sh
      # Now redo with the real bitstream cache included.
      ci/bazelisk.sh build --nobuild //...
      # This command builds all software and runs all unit tests that run on the
      # host, with a few exceptions:
      # * It excludes //quality because that's the purview of `slow_lints`.
      # * It excludes //sw/otbn/crypto because that's tested in `otbn_crypto_tests`.
      # * It excludes the tests from //third_party/riscv-compliance because
      #   they're already covered by `execute_fpga_tests_cw310`.
      # * It excludes //hw:all to avoid building Verilator, which is pulled in
      #   because //... effectively asks to build //hw:verilator_real and other
      #   targets in //hw:all that depend on it. Note that this is only a
      #   shallow exclusion; tests deeper under //hw will still be found.
      # * It excludes targets that depend on bitstream_splice rules, since the
      #   environment does not have access to Vivado.
      export GCP_BAZEL_CACHE_KEY=$(bazelCacheGcpKeyPath)
      TARGET_PATTERN_FILE=$(mktemp)
      echo //... > "${TARGET_PATTERN_FILE}"
      echo -//quality/... >> "${TARGET_PATTERN_FILE}"
      echo -//sw/otbn/crypto/... >> "${TARGET_PATTERN_FILE}"
      echo -//third_party/riscv-compliance/... >> "${TARGET_PATTERN_FILE}"
      echo -//hw:all >> "${TARGET_PATTERN_FILE}"
      ./bazelisk.sh cquery \
        --noinclude_aspects \
        --output=starlark \
        --starlark:expr='"-{}".format(target.label)' \
        --define DISABLE_VERILATOR_BUILD=true \
        -- "rdeps(//..., kind(bitstream_splice, //...))" \
        >> "${TARGET_PATTERN_FILE}"
      ci/bazelisk.sh build \
        --build_tests_only=false \
        --define DISABLE_VERILATOR_BUILD=true \
        --test_tag_filters=-broken,-cw310,-verilator,-dv \
        --target_pattern_file="${TARGET_PATTERN_FILE}"
      ci/bazelisk.sh test \
        --build_tests_only=false \
        --test_output=errors \
        --define DISABLE_VERILATOR_BUILD=true \
        --test_tag_filters=-broken,-cw310,-verilator,-dv \
        --target_pattern_file="${TARGET_PATTERN_FILE}"
    displayName: Build & test SW
  - template: ci/publish-bazel-test-results.yml
  - bash: |
      set -x -e
      . util/build_consts.sh
      # copy the rom to a specific location
      ROM_TARGET="${BIN_DIR}/sw/device/silicon_creator/rom"
      mkdir -p "${ROM_TARGET}"
      ROM_REAL_TARGETS="//sw/device/silicon_creator/rom:package_real"
      ROM_FAKE_TARGETS="//sw/device/silicon_creator/rom:package_fake"
      QUERY_CMD_ARGS=(outquery-all --noinclude_aspects --noimplicit_deps)
      ROM_REAL_FILES=($(./bazelisk.sh "${QUERY_CMD_ARGS[@]}" "${ROM_REAL_TARGETS}" | sort | uniq))
      ROM_FAKE_FILES=($(./bazelisk.sh "${QUERY_CMD_ARGS[@]}" "${ROM_FAKE_TARGETS}" | sort | uniq))
      cp -Lvt "${ROM_TARGET}" "${ROM_FAKE_FILES[@]}" "${ROM_REAL_FILES[@]}"
  - template: ci/upload-artifacts-template.yml
    parameters:
      includePatterns:
        - "/sw/***"

- job: chip_earlgrey_cw310_hyperdebug
  displayName: CW310's Earl Grey Bitstream for Hyperdebug
  # Build CW310-hyperdebug variant of the Earl Grey toplevel design using Vivado
  dependsOn:
    - lint
  condition: and(succeeded(), eq(dependencies.lint.outputs['DetermineBuildType.onlyDocChanges'], '0'), eq(dependencies.lint.outputs['DetermineBuildType.onlyDvChanges'], '0'), eq(dependencies.lint.outputs['DetermineBuildType.onlyCdcChanges'], '0'))
  pool: ci-public-eda
  timeoutInMinutes: 240
  steps:
  - template: ci/fpga-template.yml
    parameters:
      top_name: earlgrey
      design_suffix: cw310_hyperdebug

- job: execute_hyperdebug_tests_cw310
  displayName: Hyperdebug CW310 Tests (Experimental)
  pool: FPGA Staging
  timeoutInMinutes: 60
  dependsOn:
    - chip_earlgrey_cw310_hyperdebug
    - sw_build
  condition: succeeded( 'chip_earlgrey_cw310_hyperdebug', 'sw_build' )
  steps:
  - template: ci/checkout-template.yml
  - template: ci/install-package-dependencies.yml
  - template: ci/download-artifacts-template.yml
    parameters:
      downloadPartialBuildBinFrom:
        - chip_earlgrey_cw310_hyperdebug
        - sw_build
  # We run the update command twice to workaround an issue with udev on the container.
  # Where rusb cannot dynamically update its device list in CI (udev is not completely
  # functional). If the device is in normal mode, the first thing that opentitantool
  # does is to switch it to DFU mode and wait until it reconnects. This reconnection is
  # never detected. But if we run the tool another time, the device list is queried again
  # and opentitantool can finish the update. The device will now reboot in normal mode
  # and work for the hyperdebug job.
  - bash: |
      ci/bazelisk.sh run \
        //sw/host/opentitantool:opentitantool -- \
        --interface=hyperdebug_dfu transport update-firmware \
      || ci/bazelisk.sh run \
        //sw/host/opentitantool:opentitantool -- \
        --interface=hyperdebug_dfu transport update-firmware || true
    displayName: "Update the hyperdebug firmware"
  - bash: |
      set -e
      . util/build_consts.sh
      module load "xilinx/vivado/$(VIVADO_VERSION)"
      ci/scripts/run-fpga-tests.sh hyper310 hyper310 || { res=$?; echo "To reproduce failures locally, follow the instructions at https://opentitan.org/book/doc/getting_started/setup_fpga.html#reproducing-fpga-ci-failures-locally"; exit "${res}"; }
    displayName: Execute tests
  - template: ci/publish-bazel-test-results.yml
  continueOnError: True
